{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Setup\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import readline  #Import this here so that later rpy2 actually works on the cluster.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define What Class System to Analyze\n",
    "===\n",
    "Leave commented out to be determined by the Control_Commands notebook when sending to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_system = 'USPC'\n",
    "# class_system = 'IPC'\n",
    "# class_system = 'IPC4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomized_control = True\n",
    "# randomized_control = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preserve_years = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chain = 1000\n",
    "# chain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# occurrence_data = 'occurrences_organized.h5'\n",
    "# entity_data = 'entity_classes_Firm'\n",
    "# entity_column = 'Firm'\n",
    "# entity_data = 'entity_classes_Inventor'\n",
    "# entity_column = 'Inventor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# occurrence_data = 'classifications_organized.h5'\n",
    "# entity_data = 'patent_classes'\n",
    "# entity_column = 'PID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Years of History are We Using?\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_years = 1\n",
    "\n",
    "if n_years is None or n_years=='all' or n_years=='cumulative':\n",
    "    years_label = ''\n",
    "else:\n",
    "    years_label = '%i_years_'%n_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Years are We Calculating Networks for?\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target_years = 'all' #Calculate a network for every year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Import Occurrence Data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_directory = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore(data_directory+occurrence_data)\n",
    "\n",
    "entity_classes = store[entity_data+'_'+class_system].reset_index()\n",
    "\n",
    "class_lookup = store['%s_class_lookup'%class_system]\n",
    "\n",
    "store.close()\n",
    "\n",
    "#Set columns of the patent classification system we're interested in to the default names, without a class system tag.\n",
    "for column in entity_classes.columns:\n",
    "    if class_system in column:\n",
    "        new_name = column.replace('_'+class_system, \"\")\n",
    "        entity_classes.rename(columns={column: new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For each kind of entity we have a dataframe with a column name for that entity (i.e. 'Firm', 'Country', and 'Inventor').\n",
    "#Make a generic column 'Entity' in each of these dataframes with the same information.\n",
    "entity_classes.rename(columns={entity_column: 'Entity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop occurrences where data is undefined. This includes if the entity is undefined, such as \n",
    "### there being no assignee (e.g. if the patent was assigned to the inventor).\n",
    "### Class data is also undefined if the patent had been assigned to a class that is not included\n",
    "### in the set of classes we're analyzing (defined in data/class_lookup_tables.h5)\n",
    "### In practice this means about 350 patents are removed, which between them have 100 classes\n",
    "### that aren't represented anywhere else. We don't know if these small or unique classes are\n",
    "### clerical errors or if they were classes the patent office experimented with creating and\n",
    "### then dropped; all these classes are not in the current IPC system, so we treat them as noise\n",
    "### and drop them.\n",
    "\n",
    "entity_classes.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Calculate and Store Class-Class Similarity Metrics for the Empirical Networks and a Bunch of Randomized Controls\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classes = sort(list(set(citations['Class_Cited_Patent'].unique()).union(citations['Class_Citing_Patent'].unique())))\n",
    "classes = arange(len(class_lookup))\n",
    "years = sort(entity_classes['Year'].unique())\n",
    "years = list(range(min(years), max(years)+1))\n",
    "if target_years is None or target_years=='all':\n",
    "    target_years = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cooccurrence_counts(entity_classes):\n",
    "    import scipy.sparse\n",
    "    cooccurrences = scipy.sparse.csr_matrix((ones_like(entity_classes['Entity']),\n",
    "                                                      (entity_classes['Entity'], \n",
    "                                                       entity_classes['Class'])))\n",
    "\n",
    "    present_cooccurrence = (cooccurrences.T * cooccurrences).todense()\n",
    "    \n",
    "    all_cooccurrences = zeros((max(classes)+1, max(classes)+1))\n",
    "    all_cooccurrences[:present_cooccurrence.shape[0], \n",
    "                          :present_cooccurrence.shape[1]] = present_cooccurrence\n",
    "    \n",
    "    return all_cooccurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_cooccurrence_networks(entity_classes,\n",
    "                                    target_years,\n",
    "                                    classes=classes,\n",
    "                                    n_years=n_years\n",
    "                                   ):\n",
    "    networks = {}\n",
    "    for year in target_years:\n",
    "#         print(year)\n",
    "        if n_years is None or n_years=='all' or n_years=='cumulative':\n",
    "            these_entity_classes = entity_classes[entity_classes['Year']<=year]\n",
    "        else:\n",
    "            these_entity_classes = entity_classes[((entity_classes['Year']<=year) & \n",
    "                                                   (entity_classes['Year']>(year-n_years))\n",
    "                                                  )]\n",
    "        networks[year] = cooccurrence_counts(these_entity_classes)\n",
    "    return pd.Panel(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    import BiRewire as br\n",
    "\n",
    "    def randomize_occurrences(entity_classes,\n",
    "                              years=None,\n",
    "                             preserve_years=True):\n",
    "\n",
    "#         import rpy2.robjects as ro\n",
    "#         from rpy2.robjects.packages import importr\n",
    "#         from rpy2.robjects.numpy2ri import numpy2ri\n",
    "#         ro.numpy2ri.activate()\n",
    "#         importr('igraph')\n",
    "#         importr('BiRewire')\n",
    "\n",
    "\n",
    "        rewired_entity_classes = pd.DataFrame(columns=['Entity', 'Class', 'Year'],\n",
    "                                             index=range(len(entity_classes))\n",
    "                                             )\n",
    "\n",
    "        if not preserve_years:\n",
    "            entities, classes = randomize_occurrences_helper(entity_classes[['Entity', 'Class']])#, ro)\n",
    "            rewired_entity_classes['Entity'] = entities\n",
    "            rewired_entity_classes['Class'] = classes\n",
    "            rewired_entity_classes['Year'] = entity_classes['Year']\n",
    "        else:\n",
    "            if years is None:\n",
    "                years = sort(entity_classes['Year'].unique())\n",
    "\n",
    "            this_start_ind = 0\n",
    "            for target_year in years:\n",
    "#                 print(target_year)\n",
    "                these_entity_classes = entity_classes[entity_classes['Year']==target_year][['Entity', 'Class']]\n",
    "\n",
    "                entities, classes = randomize_occurrences_helper(these_entity_classes)#, ro)\n",
    "\n",
    "                n_classifications = entities.shape[0]\n",
    "\n",
    "                rewired_entity_classes.iloc[this_start_ind:n_classifications+this_start_ind, 0] = entities\n",
    "                rewired_entity_classes.iloc[this_start_ind:n_classifications+this_start_ind, 1] = classes\n",
    "                rewired_entity_classes.iloc[this_start_ind:n_classifications+this_start_ind, 2] = target_year\n",
    "\n",
    "                this_start_ind += n_classifications\n",
    "        return rewired_entity_classes.astype('int64')\n",
    "    \n",
    "    def randomize_occurrences_helper(entity_classes):#,\n",
    "#                                     ro):\n",
    "        \n",
    "        Entity_lookup = pd.Series(index=entity_classes.Entity.unique(),\n",
    "                                  data=1+arange(entity_classes.Entity.nunique()))\n",
    "        Class_lookup = pd.Series(index=entity_classes.Class.unique(),\n",
    "                                 data=1+arange(entity_classes.Class.nunique()))\n",
    "\n",
    "        n_entities = len(Entity_lookup)\n",
    "        n_classes = len(Class_lookup)\n",
    "\n",
    "        entity_classes.Entity = Entity_lookup.ix[entity_classes.Entity].values\n",
    "        entity_classes.Class = Class_lookup.ix[entity_classes.Class].values\n",
    "        entity_classes.Class += n_entities\n",
    "\n",
    "#         entity_classes = entity_classes.values.ravel(order='C')\n",
    "#         ro.globalenv['entity_classes'] = ro.Vector(entity_classes)\n",
    "#         ro.globalenv['n_entities'] = ro.default_py2ri(n_entities)\n",
    "#         ro.globalenv['n_classes'] = ro.default_py2ri(n_classes)    \n",
    "#         ro.r('g = graph.bipartite(c(rep(T, n_entities), rep(F, n_classes)), entity_classes)')\n",
    "#         ro.r('h = birewire.rewire.bipartite(g, verbose=FALSE, exact=TRUE)')\n",
    "#         z = array(ro.r('z = get.edgelist(h)')).astype('int')\n",
    "        this_rewiring = br.Rewiring(data=entity_classes.values,\n",
    "                                   type_of_array='edgelist_b',\n",
    "                                   type_of_graph='bipartite')\n",
    "        this_rewiring.rewire(verbose=0)   \n",
    "        z = this_rewiring.data_rewired\n",
    "\n",
    "        \n",
    "        Entity_lookup = pd.DataFrame(Entity_lookup).reset_index().set_index(0)\n",
    "        Class_lookup = pd.DataFrame(Class_lookup).reset_index().set_index(0)\n",
    "        \n",
    "        entities = Entity_lookup.ix[z[:,0]].values.flatten()\n",
    "        classes = Class_lookup.ix[z[:,1]-n_entities].values.flatten()\n",
    "        \n",
    "        return entities, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if randomized_control:\n",
    "    entity_classes = randomize_occurrences(entity_classes,\n",
    "                                           preserve_years=preserve_years)\n",
    "networks = calculate_cooccurrence_networks(entity_classes, target_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if randomized_control and chain: #If we have a chained randomization process, then keep going!\n",
    "    randomizations = {0: networks}\n",
    "    for iteration in range(1,chain):\n",
    "        if not iteration%100:\n",
    "            print(iteration)\n",
    "        entity_classes = randomize_occurrences(entity_classes, \n",
    "                                              preserve_years=preserve_years) \n",
    "        randomizations[iteration] = calculate_cooccurrence_networks(entity_classes, target_years)\n",
    "    networks = pd.Panel4D(randomizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "networks.major_axis = class_lookup.index[networks.major_axis]\n",
    "networks.minor_axis = class_lookup.index[networks.minor_axis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if randomized_control:    \n",
    "    if preserve_years:\n",
    "        file_name = 'synthetic_control_cooccurrence_%s%s_preserve_years_%s'%(years_label, entity_column, class_system)\n",
    "    else:\n",
    "        file_name = 'synthetic_control_cooccurrence_%s%s_no_preserve_years_%s'%(years_label, entity_column, class_system)\n",
    "    if chain:\n",
    "        file_name += '_chain.h5'\n",
    "    else:\n",
    "        file_name += '_%s.h5'%randomization_id\n",
    "    \n",
    "#     file_name = '5_years_'+file_name\n",
    "\n",
    "    store = pd.HDFStore(data_directory+'Class_Relatedness_Networks/cooccurrence/controls/%s/%s'%(class_system,file_name),\n",
    "                        mode='w', table=True)\n",
    "    store.put('/synthetic_cooccurrence_%s_%s'%(entity_column, class_system), networks, 'table', append=False)\n",
    "    store.close()\n",
    "else:\n",
    "    store = pd.HDFStore(data_directory+'Class_Relatedness_Networks/cooccurrence/class_relatedness_networks_cooccurrence.h5',\n",
    "                        mode='a', table=True)\n",
    "#     df = store['empirical_%s'%class_system]\n",
    "#     df.ix['Class_CoOccurrence_Count_%s'%entity_column] = networks\n",
    "    df = networks\n",
    "    store.put('/empirical_cooccurrence_%s%s_%s'%(years_label, entity_column, class_system), df, 'table', append=False)\n",
    "    store.close()"
   ]
  }
 ],
 "metadata": {
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
